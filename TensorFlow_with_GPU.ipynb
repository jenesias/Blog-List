{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jenesias/Blog-List/blob/main/TensorFlow_with_GPU.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tMce8muBqXQP"
      },
      "source": [
        "# Tensorflow with GPU\n",
        "\n",
        "This notebook provides an introduction to computing on a [GPU](https://cloud.google.com/gpu) in Colab. In this notebook you will connect to a GPU, and then run some basic TensorFlow operations on both the CPU and a GPU, observing the speedup provided by using the GPU.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oM_8ELnJq_wd"
      },
      "source": [
        "## Enabling and testing the GPU\n",
        "\n",
        "First, you'll need to enable GPUs for the notebook:\n",
        "\n",
        "- Navigate to Editâ†’Notebook Settings\n",
        "- select GPU from the Hardware Accelerator drop-down\n",
        "\n",
        "Next, we'll confirm that we can connect to the GPU with tensorflow:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "id": "sXnDmXR7RDr2",
        "outputId": "230c8c7a-13fd-46b3-c5b1-9c6330cfd846"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "TensorFlow 2.x selected.\n",
            "Found GPU at: /device:GPU:0\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        "  raise SystemError('GPU device not found')\n",
        "print('Found GPU at: {}'.format(device_name))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v3fE7KmKRDsH"
      },
      "source": [
        "## Observe TensorFlow speedup on GPU relative to CPU\n",
        "\n",
        "This example constructs a typical convolutional neural network layer over a\n",
        "random image and manually places the resulting ops on either the CPU or the GPU\n",
        "to compare execution speed."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y04m-jvKRDsJ",
        "outputId": "745f528f-f707-43c4-8d5c-04ace2fe615b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "nvcc: NVIDIA (R) Cuda compiler driver\n",
            "Copyright (c) 2005-2023 NVIDIA Corporation\n",
            "Built on Tue_Aug_15_22:02:13_PDT_2023\n",
            "Cuda compilation tools, release 12.2, V12.2.140\n",
            "Build cuda_12.2.r12.2/compiler.33191640_0\n"
          ]
        }
      ],
      "source": [
        "!nvcc --version\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile vector_addition_parallel.cu\n",
        "\n",
        "#include <iostream>\n",
        "#include <vector>\n",
        "#include <chrono>\n",
        "#include <cuda_runtime.h>\n",
        "\n",
        "__global__ void vectorAddParallel(float *a, float *b, float *c, int n) {\n",
        "    int i = threadIdx.x + blockDim.x * blockIdx.x;\n",
        "    if (i < n) {\n",
        "        c[i] = a[i] + b[i];\n",
        "    }\n",
        "}\n",
        "\n",
        "int main() {\n",
        "    int size = 1000 * 1000;\n",
        "    size_t size_bytes = size * sizeof(float);\n",
        "\n",
        "    std::vector<float> h_a(size, 1.0f);\n",
        "    std::vector<float> h_b(size, 2.0f);\n",
        "    std::vector<float> h_c(size);\n",
        "\n",
        "    float *d_a, *d_b, *d_c;\n",
        "\n",
        "    // Allocate memory on the device\n",
        "    cudaMalloc(&d_a, size_bytes);\n",
        "    cudaMalloc(&d_b, size_bytes);\n",
        "    cudaMalloc(&d_c, size_bytes);\n",
        "\n",
        "    // Copy vectors from host to device\n",
        "    cudaMemcpy(d_a, h_a.data(), size_bytes, cudaMemcpyHostToDevice);\n",
        "    cudaMemcpy(d_b, h_b.data(), size_bytes, cudaMemcpyHostToDevice);\n",
        "\n",
        "    // Define grid and block dimensions\n",
        "    dim3 gridSize((size + 255) / 256, 1, 1);\n",
        "    dim3 blockSize(256, 1, 1);\n",
        "\n",
        "    auto start_time = std::chrono::high_resolution_clock::now();\n",
        "\n",
        "    // Launch the vector addition kernel\n",
        "    vectorAddParallel<<<gridSize, blockSize>>>(d_a, d_b, d_c, size);\n",
        "\n",
        "    // Check for CUDA errors\n",
        "    cudaDeviceSynchronize();\n",
        "    cudaError_t cudaError = cudaGetLastError();\n",
        "    if (cudaError != cudaSuccess) {\n",
        "        std::cerr << \"CUDA error: \" << cudaGetErrorString(cudaError) << std::endl;\n",
        "        return 1;\n",
        "    }\n",
        "\n",
        "    // Copy result from device to host\n",
        "    cudaMemcpy(h_c.data(), d_c, size_bytes, cudaMemcpyDeviceToHost);\n",
        "\n",
        "    auto end_time = std::chrono::high_resolution_clock::now();\n",
        "    auto duration = std::chrono::duration_cast<std::chrono::milliseconds>(end_time - start_time);\n",
        "\n",
        "\n",
        "\n",
        "    std::cout << \"Parallel Vector Addition took \" << duration.count() << \" milliseconds.\\n\";\n",
        "\n",
        "    // Free memory on the device\n",
        "    cudaFree(d_a);\n",
        "    cudaFree(d_b);\n",
        "    cudaFree(d_c);\n",
        "\n",
        "    return 0;\n",
        "}\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3_-WgCPPg-k1",
        "outputId": "2129a95b-67da-4612-aea5-45fb560e400a"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting vector_addition_parallel.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc vector_addition_parallel.cu -o vector_addition_parallel\n",
        "!./vector_addition_parallel\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0B83IILdhCyz",
        "outputId": "ee5197dd-b1c8-49a2-8073-53fbd6f693fd"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Parallel Vector Addition took 1 milliseconds.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "MzWwL04chHmz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile vector_addition_sequential.cpp\n",
        "\n",
        "#include <iostream>\n",
        "#include <vector>\n",
        "#include <chrono>\n",
        "\n",
        "void vectorAddSequential(const std::vector<float>& a, const std::vector<float>& b, std::vector<float>& c) {\n",
        "    int n = a.size();\n",
        "    for (int i = 0; i < n; ++i) {\n",
        "        c[i] = a[i] + b[i];\n",
        "    }\n",
        "}\n",
        "\n",
        "int main() {\n",
        "    int size = 1000 * 1000;\n",
        "\n",
        "    std::vector<float> h_a(size, 1.0f);\n",
        "    std::vector<float> h_b(size, 2.0f);\n",
        "    std::vector<float> h_c(size);\n",
        "\n",
        "    auto start_time = std::chrono::high_resolution_clock::now();\n",
        "\n",
        "    vectorAddSequential(h_a, h_b, h_c);\n",
        "\n",
        "    auto end_time = std::chrono::high_resolution_clock::now();\n",
        "    auto duration = std::chrono::duration_cast<std::chrono::milliseconds>(end_time - start_time);\n",
        "\n",
        "    // Print the result (printing first 10 elements)\n",
        "\n",
        "\n",
        "\n",
        "    std::cout << \"Sequential Vector Addition took \" << duration.count() << \" milliseconds.\\n\";\n",
        "\n",
        "    return 0;\n",
        "}\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yzYVDECMhQFE",
        "outputId": "42f9f604-af56-4407-82b5-d67ca2e06000"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting vector_addition_sequential.cpp\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!g++ vector_addition_sequential.cpp -o vector_addition_sequential\n",
        "!./vector_addition_sequential\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cYbn-qMKhTuc",
        "outputId": "88591466-78ae-46d1-b300-d13e7d890abe"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sequential Vector Addition took 7 milliseconds.\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "TensorFlow with GPU",
      "toc_visible": true,
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}